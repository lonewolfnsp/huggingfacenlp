{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis using the emotion dataset with 6 emotions\n",
    "native pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "chkpt=\"distilbert-base-uncased\"\n",
    "saveModeldir=\"saved-model\"\n",
    "\n",
    "tokenizer=AutoTokenizer.from_pretrained(chkpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the emotion dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"emotion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes={}\n",
    "for i, mood in enumerate(ds['train'].features['label'].names):\n",
    "    classes[i]=mood    \n",
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's see examples of each emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mood=0 \n",
    "\n",
    "for i in range (100):\n",
    "    if ds['train']['label'][i] ==mood:\n",
    "        s=ds['train']['text'][i]\n",
    "        print(f'{classes[mood]}: {s}  ')\n",
    "        mood+=1\n",
    "        if mood==6:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the dataset to make it compatible with model's tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "\n",
    "checkpoint = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "def tokenize_fn(sample):\n",
    "    return tokenizer(sample['text'], truncation=True)\n",
    "\n",
    "tokenized_ds = ds.map(tokenize_fn, batched=True)\n",
    "\n",
    "# remove unwanted columns that miodel is not expecting. renaming column so model can expect it\n",
    "\n",
    "tokenized_ds=tokenized_ds.remove_columns('text')\n",
    "tokenized_ds=tokenized_ds.rename_column('label', 'labels')\n",
    "tokenized_ds\n",
    "tokenized_ds['train'].column_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using DataCollator with DataLoader\n",
    "\n",
    "### DataCp;;ator provides dynamic padding. Wehn combined with dataloader, the amount of padding to use depends on the longest sentence in the current batch. This only works when using GPU, and pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batchSize=128\n",
    "\n",
    "collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "train_dl = DataLoader(tokenized_ds[\"train\"], shuffle=True, batch_size=batchSize, collate_fn=collator)\n",
    "eval_dl = DataLoader(tokenized_ds[\"validation\"], batch_size=batchSize, collate_fn=collator)\n",
    "test_dl= DataLoader(tokenized_ds[\"test\"], batch_size=batchSize, collate_fn=collator)\n",
    "\n",
    "print(f'train dl has {len(train_dl) }  batches')\n",
    "print(f'validation dl has {len(eval_dl) }  batches')\n",
    "print(f'test dl has {len(test_dl) }  batches')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch=next(iter(train_dl))\n",
    "{k: v.shape for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notice how the 2nd dimension of the batch changes between batches? that's dynamic padding thanks to the data collator.\n",
    "\n",
    "## Importing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(chkpt, num_labels=len(classes), id2label=classes)\n",
    "model.config.id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try with a batch first to test if model can process a batch\n",
    "outputs = model(**batch)\n",
    "print(outputs.loss, outputs.logits.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "\n",
    "lr=1e-4\n",
    "epochs=5\n",
    "totalSteps=math.ceil(ds['train'].num_rows/batchSize)*epochs\n",
    "print(f'training has {totalSteps} total steps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## importing optimizer and learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "from transformers import get_scheduler\n",
    "\n",
    "opt=AdamW(model.parameters(), lr=lr)\n",
    "scheduler = get_scheduler(\"cosine\",optimizer=opt,num_warmup_steps=0,num_training_steps=totalSteps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup device to use GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device \n",
    "model.to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAccuracy(outs, batch):\n",
    "    preds=torch.argmax(outs.logits, dim=1)\n",
    "    y=torch.sum(preds==batch['labels']).item()\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "\n",
    "def train():\n",
    "    losses=0.\n",
    "    accs=0\n",
    "    model.train() \n",
    "    torch.set_grad_enabled(True)   \n",
    "\n",
    "    for batch in tqdm(train_dl):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        losses+=(loss.item() *len(batch['labels']))\n",
    "        accs+=getAccuracy(outputs, batch)\n",
    "        loss.backward()        \n",
    "        opt.step()\n",
    "        scheduler.step()\n",
    "        opt.zero_grad()\n",
    "    return losses/ds['train'].num_rows , accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "\n",
    "def evaluate(ldr):\n",
    "    losses=0. \n",
    "    accs=0\n",
    "    model.eval()\n",
    "    torch.set_grad_enabled(False)\n",
    "    \n",
    "    for batch in tqdm(ldr):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss.item()\n",
    "        losses+=(loss*len(batch['labels']))\n",
    "        accs+=getAccuracy(outputs, batch)    \n",
    "    return losses/ds['validation'].num_rows , accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as display \n",
    "\n",
    "\n",
    "def showResults(TLosses, TAccs, VLosses, VAccs):\n",
    "    display.clear_output(wait=True)        \n",
    "    print('epoch\\tTLoss\\t\\t TAcc\\t\\t ValLoss\\t ValAcc\\n')\n",
    "    i=1\n",
    "    for tl, ta, vl, va in zip(TLosses, TAccs, VLosses, VAccs) :\n",
    "        print(f'{i}\\t {tl:.3f}\\t\\t {ta*100.:.3f}%\\t {vl:.3f}\\t\\t {va*100.:.3f}% ')\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "TrainLosses=[]\n",
    "TrainAccs=[]\n",
    "valLosses=[]\n",
    "valAccs=[]\n",
    "\n",
    "totalTrain=len(ds['train'])\n",
    "totalVal=len(ds['validation'] )\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f'epoch: {epoch+1} / {epochs}  ')\n",
    "    print('training...')\n",
    "    loss, accs=train()\n",
    "    TrainLosses.append(loss)\n",
    "    acc=accs/totalTrain \n",
    "    TrainAccs.append(acc)\n",
    "    \n",
    "    #test validation set\n",
    "    print('evaluating...')\n",
    "    loss, accs=evaluate(eval_dl)\n",
    "    acc=accs/totalVal\n",
    "    valLosses.append(loss)\n",
    "    valAccs.append(acc)    \n",
    "    showResults(TrainLosses, TrainAccs, valLosses, valAccs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's plot the losses and accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "plt.figure(figsize=(20,20) )\n",
    "plt.subplot(1,2,1)\n",
    "plt.title('Losses')\n",
    "plt.plot(TrainLosses, label='train')\n",
    "plt.plot(valLosses,label='val')\n",
    "plt.legend()\n",
    "plt.subplot(1,2,2)\n",
    "plt.title('Accuracies')\n",
    "plt.plot(TrainAccs, label='train')\n",
    "plt.plot(valAccs, label='val')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc=evaluate(test_dl)\n",
    "acc=acc/len(ds['test'])\n",
    "print(f'test accuracy={acc*100.:.3f} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(saveModeldir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification \n",
    "\n",
    "model2= AutoModelForSequenceClassification.from_pretrained(saveModeldir)\n",
    "#model2.config\n",
    "model2.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMood(samples):\n",
    "    input=tokenizer(samples,padding=True, truncation=True, return_tensors=\"pt\" ).to(device)\n",
    "    out=model2(**input)\n",
    "    res=torch.argmax(out.logits , dim=1)    \n",
    "    return res.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str1=\"i am really annoyed\"\n",
    "str2=\"my heart yearns for her return\"\n",
    "str3=\"my heart is torn apart\"\n",
    "str4=\"it's a great sunday today\"\n",
    "str5=\"i'm left speechless\"\n",
    "str6=\"i stepped into the unknown\"\n",
    "\n",
    "strs=[str1, str2, str3, str4, str5, str6]\n",
    "\n",
    "out=getMood(strs)\n",
    "\n",
    "for i, res in enumerate(out):\n",
    "    print(f'{strs[i]}: {model2.config.id2label[res.item()]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dd5645910c9f12221763b2aa836bb1f3cb241427948cb3afce762a164a0fd337"
  },
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
