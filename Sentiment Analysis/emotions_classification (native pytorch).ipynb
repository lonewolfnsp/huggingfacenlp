{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis using the emotion dataset with 6 emotions\n",
    "### native pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "chkpt=\"distilbert-base-uncased\"\n",
    "saveModeldir=\"saved-model\"\n",
    "\n",
    "tokenizer=AutoTokenizer.from_pretrained(chkpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the emotion dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"emotion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes={}\n",
    "for i, mood in enumerate(ds['train'].features['label'].names):\n",
    "    classes[i]=mood    \n",
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's see examples of each emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mood=0 \n",
    "\n",
    "for i in range (100):\n",
    "    if ds['train']['label'][i] ==mood:\n",
    "        s=ds['train']['text'][i]\n",
    "        print(f'{classes[mood]}: {s}  ')\n",
    "        mood+=1\n",
    "        if mood==6:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the dataset to make it compatible with model's tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "\n",
    "checkpoint = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "def tokenize_fn(sample):\n",
    "    return tokenizer(sample['text'], truncation=True)\n",
    "\n",
    "tokenized_ds = ds.map(tokenize_fn, batched=True)\n",
    "\n",
    "# remove unwanted columns that miodel is not expecting. renaming column so model can expect it\n",
    "\n",
    "tokenized_ds=tokenized_ds.remove_columns('text')\n",
    "tokenized_ds=tokenized_ds.rename_column('label', 'labels')\n",
    "tokenized_ds\n",
    "tokenized_ds['train'].column_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using DataCollator with DataLoader\n",
    "\n",
    "### DataCp;;ator provides dynamic padding. Wehn combined with dataloader, the amount of padding to use depends on the longest sentence in the current batch. This only works when using GPU, and pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batchSize=128\n",
    "\n",
    "collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "train_dl = DataLoader(tokenized_ds[\"train\"], shuffle=True, batch_size=batchSize, collate_fn=collator)\n",
    "eval_dl = DataLoader(tokenized_ds[\"validation\"], batch_size=batchSize, collate_fn=collator)\n",
    "test_dl= DataLoader(tokenized_ds[\"test\"], batch_size=batchSize, collate_fn=collator)\n",
    "\n",
    "print(f'train dl has {len(train_dl) }  batches')\n",
    "print(f'validation dl has {len(eval_dl) }  batches')\n",
    "print(f'test dl has {len(test_dl) }  batches')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch=next(iter(train_dl))\n",
    "{k: v.shape for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notice how the 2nd dimension of the batch changes between batches? that's dynamic padding thanks to the data collator.\n",
    "\n",
    "## Importing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(chkpt, num_labels=len(classes), id2label=classes)\n",
    "model.config.id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try with a batch first to test if model can process a batch\n",
    "outputs = model(**batch)\n",
    "print(outputs.loss, outputs.logits.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr= 8e-5\n",
    "epochs=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## importing optimizer and learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "from transformers import get_scheduler\n",
    "\n",
    "opt=AdamW(model.parameters(), lr=lr)\n",
    "scheduler = get_scheduler(\"linear\", optimizer=opt,num_warmup_steps=len(train_dl)*4,num_training_steps= len(train_dl)*epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup device to use GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device \n",
    "model.to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAccuracy(outs, batch):\n",
    "    preds=torch.argmax(outs.logits, dim=1)\n",
    "    y=torch.sum(preds==batch['labels']).item()\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "\n",
    "def train(optim, sched=None):\n",
    "    losses=0.\n",
    "    accs=0\n",
    "    model.train() \n",
    "    torch.set_grad_enabled(True)   \n",
    "\n",
    "    for batch in tqdm(train_dl):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        losses+=(loss.item() *len(batch['labels']))\n",
    "        accs+=getAccuracy(outputs, batch)\n",
    "        loss.backward()        \n",
    "        optim.step()\n",
    "        if sched is not None:\n",
    "            sched.step()\n",
    "        opt.zero_grad()\n",
    "    return losses/ds['train'].num_rows , accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "\n",
    "def evaluate(ldr, trainedModel):\n",
    "    losses=0. \n",
    "    accs=0\n",
    "    model.eval()\n",
    "    torch.set_grad_enabled(False)\n",
    "    \n",
    "    for batch in tqdm(ldr):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = trainedModel(**batch)\n",
    "        loss = outputs.loss.item()\n",
    "        losses+=(loss*len(batch['labels']))\n",
    "        accs+=getAccuracy(outputs, batch)    \n",
    "    return losses/ds['validation'].num_rows , accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as display \n",
    "\n",
    "\n",
    "def showResults(TLosses, TAccs, VLosses, VAccs):\n",
    "    display.clear_output(wait=True)        \n",
    "    print('epoch\\tTLoss\\t\\t TAcc\\t\\t ValLoss\\t ValAcc\\n')\n",
    "    i=1\n",
    "    for tl, ta, vl, va in zip(TLosses, TAccs, VLosses, VAccs) :\n",
    "        print(f'{i}\\t {tl:.3f}\\t\\t {ta*100.:.3f}%\\t {vl:.3f}\\t\\t {va*100.:.3f}% ')\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "TrainLosses=[]\n",
    "TrainAccs=[]\n",
    "valLosses=[]\n",
    "valAccs=[]\n",
    "curValAcc=0.0 \n",
    "curEp=-1\n",
    "\n",
    "totalTrain=len(ds['train'])\n",
    "totalVal=len(ds['validation'] )\n",
    "\n",
    "for ep  in range(epochs):\n",
    "    print(f'epoch: {ep+1} / {epochs}  ')\n",
    "    print('training...')\n",
    "    loss, accs=train(opt, scheduler)\n",
    "    TrainLosses.append(loss)\n",
    "    acc=accs/totalTrain \n",
    "    TrainAccs.append(acc)\n",
    "    \n",
    "    #test validation set\n",
    "    print('evaluating...')\n",
    "    loss, accs=evaluate(eval_dl, model)\n",
    "    acc=accs/totalVal\n",
    "    valLosses.append(loss)\n",
    "    valAccs.append(acc) \n",
    "    if curValAcc < acc:   \n",
    "        curValAcc = acc\n",
    "        curEp=ep \n",
    "        model.save_pretrained(saveModeldir)\n",
    "    showResults(TrainLosses, TrainAccs, valLosses, valAccs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's plot the losses and accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "plt.figure(figsize=(20,20) )\n",
    "plt.subplot(1,2,1)\n",
    "plt.title('Losses')\n",
    "plt.plot(TrainLosses, label='train')\n",
    "plt.plot(valLosses,label='val')\n",
    "plt.legend()\n",
    "plt.subplot(1,2,2)\n",
    "plt.title('Accuracies')\n",
    "plt.plot(TrainAccs, label='train')\n",
    "plt.plot(valAccs, label='val')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the best performing model for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=6, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "model2=AutoModelForSequenceClassification.from_pretrained(\"saved-model\")\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu' )\n",
    "model2.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate with test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc=evaluate(test_dl, model2)\n",
    "acc=acc/len(ds['test'])\n",
    "print(f'test accuracy={acc*100.:.3f} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMood(samples):\n",
    "    input=tokenizer(samples,padding=True, truncation=True, return_tensors=\"pt\" ).to(device)\n",
    "    out=model2(**input)\n",
    "    res=torch.argmax(out.logits , dim=1)    \n",
    "    return res.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i am really annoyed: anger\n",
      "my heart yearns for her return: love\n",
      "my heart is torn apart: sadness\n",
      "it's a great sunday today: joy\n",
      "i'm left speechless: surprise\n",
      "i stepped into the unknown: fear\n"
     ]
    }
   ],
   "source": [
    "str1=\"i am really annoyed\"\n",
    "str2=\"my heart yearns for her return\"\n",
    "str3=\"my heart is torn apart\"\n",
    "str4=\"it's a great sunday today\"\n",
    "str5=\"i'm left speechless\"\n",
    "str6=\"i stepped into the unknown\"\n",
    "\n",
    "strs=[str1, str2, str3, str4, str5, str6]\n",
    "\n",
    "out=getMood(strs)\n",
    "\n",
    "for i, res in enumerate(out):\n",
    "    print(f'{strs[i]}: {model2.config.id2label[res.item()]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dd5645910c9f12221763b2aa836bb1f3cb241427948cb3afce762a164a0fd337"
  },
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
